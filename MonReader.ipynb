{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Table of Content</b>\n",
    "\n",
    "0. Import functions\n",
    "\n",
    "1. Download ZIP file from Google Drive and unzip in into local drive\n",
    "\n",
    "2. Load image files and convert them into arrays"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>0. Import functions</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.load import check_file_downloaded, extract_zip_file, load_images\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>1. Download ZIP file from Google Drive and unzip in into local drive</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Details of the source file in G Drive\n",
    "file_id = \"1KDQBTbo5deKGCdVV_xIujscn5ImxW4dm\"\n",
    "file_url = f\"https://drive.google.com/file/d/{file_id}\"\n",
    "zip_file_name = \"images.zip\"\n",
    "\n",
    "# Details of local directories\n",
    "root_path = os.getcwd()\n",
    "download_path = root_path + \"\\\\\" + \"data\"\n",
    "zip_file_path = download_path + \"\\\\\" + zip_file_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the source file from G Drive if the file does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File images.zip already exists in c:\\Users\\Admin\\Documents\\GitHub\\Apziva\\lnaNWaYIRf6JhvHJ\\data.\n"
     ]
    }
   ],
   "source": [
    "os.chdir(download_path)\n",
    "file_exists = os.path.exists(zip_file_name)\n",
    "if file_exists:\n",
    "    print(f\"File {zip_file_name} already exists in {download_path}.\")\n",
    "else:\n",
    "    print(\"Downloading file from Google Drive.\")\n",
    "    print(\"This could take a few minutes.\")\n",
    "    !gdown 1KDQBTbo5deKGCdVV_xIujscn5ImxW4dm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the downloading was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File images.zip exist in c:\\Users\\Admin\\Documents\\GitHub\\Apziva\\lnaNWaYIRf6JhvHJ\\data!\n"
     ]
    }
   ],
   "source": [
    "check_file_downloaded(file_name=zip_file_name, default_path=root_path, download_path=download_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images.zip already extracted in c:\\Users\\Admin\\Documents\\GitHub\\Apziva\\lnaNWaYIRf6JhvHJ\\data.\n"
     ]
    }
   ],
   "source": [
    "extract_zip_file(zip_file_path, download_path, zip_file_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>2. Load image files and convert them into arrays</b>\n",
    "\n",
    "Load images as is for efficiency and memory saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files in c:\\Users\\Admin\\Documents\\GitHub\\Apziva\\lnaNWaYIRf6JhvHJ\\data\\images\n",
      "Loading files in c:\\Users\\Admin\\Documents\\GitHub\\Apziva\\lnaNWaYIRf6JhvHJ\\data\\images\\testing\n",
      "Loading files in c:\\Users\\Admin\\Documents\\GitHub\\Apziva\\lnaNWaYIRf6JhvHJ\\data\\images\\testing\\flip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 290/290 [00:00<00:00, 727.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files in c:\\Users\\Admin\\Documents\\GitHub\\Apziva\\lnaNWaYIRf6JhvHJ\\data\\images\\testing\\notflip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:00<00:00, 1346.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files in c:\\Users\\Admin\\Documents\\GitHub\\Apziva\\lnaNWaYIRf6JhvHJ\\data\\images\\training\n",
      "Loading files in c:\\Users\\Admin\\Documents\\GitHub\\Apziva\\lnaNWaYIRf6JhvHJ\\data\\images\\training\\flip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1162/1162 [00:01<00:00, 703.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files in c:\\Users\\Admin\\Documents\\GitHub\\Apziva\\lnaNWaYIRf6JhvHJ\\data\\images\\training\\notflip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1230/1230 [00:01<00:00, 872.76it/s]\n"
     ]
    }
   ],
   "source": [
    "array_dict = load_images(download_path, as_array=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 1080, 3)\n"
     ]
    }
   ],
   "source": [
    "from numpy import asarray\n",
    "\n",
    "# image = Image.open(jpg_file_path) <= values in the dict\n",
    "for k, v in array_dict[\"testing\"][\"flip\"].items():\n",
    "    image_array = asarray(v)\n",
    "    image_shape = image_array.shape\n",
    "    print(image_shape)\n",
    "    break\n",
    "# Image.fromarray(image_array) # To revert back from array to image\n",
    "\n",
    "# file_name = VideoID_FrameNumber"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly sample one third of training data to get around memory issues due to a large number of image arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# from numpy import asarray\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# if not os.path.exists(\"./data/train_data.npy\"):\n",
    "#     print(\"train_data.npy does not exist. Create the file.\")\n",
    "#     import random\n",
    "#     random.seed(1)\n",
    "\n",
    "#     train_flip_sampled = random.sample(\n",
    "#         list(array_dict[\"training\"][\"flip\"].values()),\n",
    "#         int(len(array_dict[\"training\"][\"flip\"])/3)\n",
    "#         )\n",
    "#     train_notflip_sampled = random.sample(\n",
    "#         list(array_dict[\"training\"][\"notflip\"].values()),\n",
    "#         int(len(array_dict[\"training\"][\"notflip\"])/3)\n",
    "#         )\n",
    "\n",
    "#     train_data = []\n",
    "#     for i, img_list in enumerate([train_flip_sampled, train_notflip_sampled]):\n",
    "#         label_code = 1 # flip\n",
    "#         if i == 1:\n",
    "#             label_code = 0 # notflip\n",
    "\n",
    "#         for img in tqdm(img_list):\n",
    "#             image_array = asarray(img)\n",
    "#             train_data.append([image_array, label_code])\n",
    "\n",
    "#     np.save(\"./data/train_data.npy\", train_data)\n",
    "#     print(\"train_data saved.\")\n",
    "#     len(train_data)\n",
    "\n",
    "# else:\n",
    "#     print(\"train_data.npy already exists. Loading the file.\")\n",
    "#     train_data = np.load(\"./data/train_data.npy\", allow_pickle=True)\n",
    "#     print(\"train_data loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists(\"./data/test_data.npy\"):\n",
    "#     print(\"test_data.npy does not exist. Create the file.\")\n",
    "#     test_data = []\n",
    "#     for label in [\"flip\", \"notflip\"]:\n",
    "#         label_code = 1\n",
    "#         if label == \"notflip\":\n",
    "#             label_code = 0\n",
    "#         for name, img in tqdm(array_dict[\"testing\"][label].items()):\n",
    "#             image_array = asarray(img)\n",
    "#             test_data.append([image_array, label_code])\n",
    "\n",
    "#     np.save(\"./data/test_data.npy\", test_data)\n",
    "#     print(\"test_data saved.\")\n",
    "#     len(test_data)\n",
    "\n",
    "# else:\n",
    "#     print(\"test_data.npy already exists. Loading the file.\")\n",
    "#     test_data = np.load(\"./data/test_data.npy\", allow_pickle=True)\n",
    "#     print(\"test_data loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/python-image-classification-using-keras/\n",
    "\n",
    "# Importing all necessary libraries\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "img_width, img_height = image_shape[:2]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (2, 2), input_shape=image_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2392 images belonging to 2 classes.\n",
      "Found 597 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = './data/images/training'\n",
    "validation_data_dir = './data/images/testing'\n",
    "nb_train_samples = len(array_dict[\"training\"][\"flip\"]) + len(array_dict[\"training\"][\"notflip\"])\n",
    "nb_validation_samples = len(array_dict[\"testing\"][\"flip\"]) + len(array_dict[\"testing\"][\"notflip\"])\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "\trescale=1. / 255,\n",
    "\tshear_range=0.2,\n",
    "\tzoom_range=0.2,\n",
    "\thorizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "\ttrain_data_dir,\n",
    "\ttarget_size=(img_width, img_height),\n",
    "\t# target_size=image_shape,\n",
    "\tbatch_size=batch_size,\n",
    "\tclass_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "\tvalidation_data_dir,\n",
    "\ttarget_size=(img_width, img_height),\n",
    "\t# target_size=image_shape,\n",
    "\tbatch_size=batch_size,\n",
    "\tclass_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "\ttrain_generator,\n",
    "\tsteps_per_epoch=nb_train_samples // batch_size,\n",
    "\tepochs=epochs,\n",
    "\tvalidation_data=validation_generator,\n",
    "\tvalidation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('model_saved.h5')\n",
    "\n",
    "image = load_img('v_data/test/planes/5.jpg', target_size=(224, 224))\n",
    "img = np.array(image)\n",
    "img = img / 255.0\n",
    "img = img.reshape(1,224,224,3)\n",
    "label = model.predict(img)\n",
    "print(\"Predicted Class (0 - Cars , 1- Planes): \", label[0][0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.geeksforgeeks.org/python-image-classification-using-keras/\n",
    "\n",
    "https://medium.com/techiepedia/binary-image-classifier-cnn-using-tensorflow-a3f5d6746697"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tflearn\\initializations.py:110: calling UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:561: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "WARNING:tensorflow:From c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tflearn\\initializations.py:164: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# # Python program to create\n",
    "# # Image Classifier using CNN\n",
    "\n",
    "# # Importing the required libraries\n",
    "# import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# '''Setting up the env'''\n",
    "\n",
    "# TRAIN_DIR = 'E:/dataset / Cats_vs_Dogs / train'\n",
    "# TEST_DIR = 'E:/dataset / Cats_vs_Dogs / test1'\n",
    "# IMG_SIZE = 50\n",
    "LR = 1e-3\n",
    "\n",
    "\n",
    "# '''Setting up the model which will help with tensorflow models'''\n",
    "# MODEL_NAME = 'dogsvscats-{}-{}.model'.format(LR, '6conv-basic')\n",
    "\n",
    "# '''Labelling the dataset'''\n",
    "# def label_img(img):\n",
    "# \tword_label = img.split('.')[-3]\n",
    "# \t# DIY One hot encoder\n",
    "# \tif word_label == 'cat': return [1, 0]\n",
    "# \telif word_label == 'dog': return [0, 1]\n",
    "\n",
    "# '''Creating the training data'''\n",
    "# def create_train_data():\n",
    "# \t# Creating an empty list where we should store the training data\n",
    "# \t# after a little preprocessing of the data\n",
    "# \ttraining_data = []\n",
    "\n",
    "# \t# tqdm is only used for interactive loading\n",
    "# \t# loading the training data\n",
    "# \tfor img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "\n",
    "# \t\t# labeling the images\n",
    "# \t\tlabel = label_img(img)\n",
    "\n",
    "# \t\tpath = os.path.join(TRAIN_DIR, img)\n",
    "\n",
    "# \t\t# loading the image from the path and then converting them into\n",
    "# \t\t# grayscale for easier covnet prob\n",
    "# \t\timg = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# \t\t# resizing the image for processing them in the covnet\n",
    "# \t\timg = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "# \t\t# final step-forming the training data list with numpy array of the images\n",
    "# \t\ttraining_data.append([np.array(img), np.array(label)])\n",
    "\n",
    "# \t# shuffling of the training data to preserve the random state of our data\n",
    "# \tshuffle(training_data)\n",
    "\n",
    "# \t# saving our trained data for further uses if required\n",
    "# \tnp.save('train_data.npy', training_data)\n",
    "# \treturn training_data\n",
    "\n",
    "# '''Processing the given test data'''\n",
    "# # Almost same as processing the training data but\n",
    "# # we dont have to label it.\n",
    "# def process_test_data():\n",
    "# \ttesting_data = []\n",
    "# \tfor img in tqdm(os.listdir(TEST_DIR)):\n",
    "# \t\tpath = os.path.join(TEST_DIR, img)\n",
    "# \t\timg_num = img.split('.')[0]\n",
    "# \t\timg = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "# \t\timg = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "# \t\ttesting_data.append([np.array(img), img_num])\n",
    "\t\t\n",
    "# \tshuffle(testing_data)\n",
    "# \tnp.save('test_data.npy', testing_data)\n",
    "# \treturn testing_data\n",
    "\n",
    "# '''Running the training and the testing in the dataset for our model'''\n",
    "# train_data = create_train_data()\n",
    "# test_data = process_test_data()\n",
    "\n",
    "# # train_data = np.load('train_data.npy')\n",
    "# # test_data = np.load('test_data.npy')\n",
    "'''Creating the neural network using tensorflow'''\n",
    "# Importing the required libraries\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.reset_default_graph()\n",
    "convnet = input_data(shape =[None, 1920, 1080, 3], name ='input')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation ='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "# convnet = conv_2d(convnet, 64, 5, activation ='relu')\n",
    "# convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "# convnet = conv_2d(convnet, 128, 5, activation ='relu')\n",
    "# convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "# convnet = conv_2d(convnet, 64, 5, activation ='relu')\n",
    "# convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "# convnet = conv_2d(convnet, 32, 5, activation ='relu')\n",
    "# convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation ='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 2, activation ='softmax')\n",
    "convnet = regression(convnet, optimizer ='adam', learning_rate = LR,\n",
    "\tloss ='categorical_crossentropy', name ='targets')\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir ='log')\n",
    "\n",
    "# Splitting the testing data and training data\n",
    "# train = train_data[:-500]\n",
    "# test = train_data[-500:]\n",
    "\n",
    "'''Setting up the features and labels'''\n",
    "# X-Features & Y-Labels\n",
    "\n",
    "train_X = np.array([i[0] for i in train_data]).reshape(-1, 1920, 1080, 3)\n",
    "train_y = np.array([i[1] for i in train_data])\n",
    "test_X = np.array([i[0] for i in test_data]).reshape(-1, 1920, 1080, 3)\n",
    "test_y = np.array([i[1] for i in test_data])\n",
    "\n",
    "'''Fitting the data into our model'''\n",
    "# epoch = 5 taken\n",
    "model.fit({'input': train_X}, {'targets': train_y}, n_epoch = 5,\n",
    "\tvalidation_set =({'input': test_X}, {'targets': test_y}),\n",
    "\tsnapshot_step = 500, show_metric = True, run_id = \"initial.model\")\n",
    "model.save(\"initial.model\")\n",
    "\n",
    "'''Testing the data'''\n",
    "import matplotlib.pyplot as plt\n",
    "# if you need to create the data:\n",
    "# test_data = process_test_data()\n",
    "# if you already have some saved:\n",
    "test_data = np.load('test_data.npy')\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for num, data in enumerate(test_data[:20]):\n",
    "\t# cat: [1, 0]\n",
    "\t# dog: [0, 1]\n",
    "\t\n",
    "\timg_num = data[1]\n",
    "\timg_data = data[0]\n",
    "\t\n",
    "\ty = fig.add_subplot(4, 5, num + 1)\n",
    "\torig = img_data\n",
    "\tdata = img_data.reshape(1920, 1080, 3)\n",
    "\n",
    "\t# model_out = model.predict([data])[0]\n",
    "\tmodel_out = model.predict([data])[0]\n",
    "\t\n",
    "\tif np.argmax(model_out) == 1: str_label ='Dog'\n",
    "\telse: str_label ='Cat'\n",
    "\t\t\n",
    "\ty.imshow(orig, cmap ='gray')\n",
    "\tplt.title(str_label)\n",
    "\ty.axes.get_xaxis().set_visible(False)\n",
    "\ty.axes.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
