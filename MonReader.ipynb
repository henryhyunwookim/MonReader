{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Table of Content</b>\n",
    "\n",
    "0. Import functions\n",
    "\n",
    "1. Download ZIP file from Google Drive and unzip in into local drive\n",
    "\n",
    "2. Load image files and convert them into arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>0. Import functions</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.load import check_file_downloaded, extract_zip_file, load_images\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>1. Download ZIP file from Google Drive and unzip in into local drive</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Details of the source file in G Drive\n",
    "file_id = \"1KDQBTbo5deKGCdVV_xIujscn5ImxW4dm\"\n",
    "file_url = f\"https://drive.google.com/file/d/{file_id}\"\n",
    "zip_file_name = \"images.zip\"\n",
    "\n",
    "# Details of local directories\n",
    "root_path = os.getcwd()\n",
    "download_path = root_path + \"\\\\\" + \"data\"\n",
    "zip_file_path = download_path + \"\\\\\" + zip_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the source file from G Drive if the file does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File images.zip already exists in c:\\Users\\Admin\\Documents\\GitHub\\Apziva\\lnaNWaYIRf6JhvHJ\\data.\n"
     ]
    }
   ],
   "source": [
    "os.chdir(download_path)\n",
    "file_exists = os.path.exists(zip_file_name)\n",
    "if file_exists:\n",
    "    print(f\"File {zip_file_name} already exists in {download_path}.\")\n",
    "else:\n",
    "    print(\"Downloading file from Google Drive.\")\n",
    "    print(\"This could take a few minutes.\")\n",
    "    !gdown 1KDQBTbo5deKGCdVV_xIujscn5ImxW4dm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the downloading was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File images.zip exist in c:\\Users\\Admin\\Documents\\GitHub\\Apziva\\lnaNWaYIRf6JhvHJ\\data!\n"
     ]
    }
   ],
   "source": [
    "check_file_downloaded(file_name=zip_file_name, default_path=root_path, download_path=download_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images.zip already extracted in c:\\Users\\Admin\\Documents\\GitHub\\Apziva\\lnaNWaYIRf6JhvHJ\\data.\n"
     ]
    }
   ],
   "source": [
    "extract_zip_file(zip_file_path, download_path, zip_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>2. Load image files and convert them into arrays</b>\n",
    "\n",
    "Load images as is for efficiency and memory saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files in c:\\Users\\Admin\\Documents\\GitHub\\Apziva\\lnaNWaYIRf6JhvHJ\\data\\images\n",
      "Loading files in c:\\Users\\Admin\\Documents\\GitHub\\Apziva\\lnaNWaYIRf6JhvHJ\\data\\images\\testing\n",
      "Loading files in c:\\Users\\Admin\\Documents\\GitHub\\Apziva\\lnaNWaYIRf6JhvHJ\\data\\images\\testing\\flip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 290/290 [00:00<00:00, 1652.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files in c:\\Users\\Admin\\Documents\\GitHub\\Apziva\\lnaNWaYIRf6JhvHJ\\data\\images\\testing\\notflip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:00<00:00, 2183.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files in c:\\Users\\Admin\\Documents\\GitHub\\Apziva\\lnaNWaYIRf6JhvHJ\\data\\images\\training\n",
      "Loading files in c:\\Users\\Admin\\Documents\\GitHub\\Apziva\\lnaNWaYIRf6JhvHJ\\data\\images\\training\\flip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1162/1162 [00:00<00:00, 1806.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files in c:\\Users\\Admin\\Documents\\GitHub\\Apziva\\lnaNWaYIRf6JhvHJ\\data\\images\\training\\notflip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1230/1230 [00:00<00:00, 1787.31it/s]\n"
     ]
    }
   ],
   "source": [
    "array_dict = load_images(download_path, as_array=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 1080, 3)\n"
     ]
    }
   ],
   "source": [
    "from numpy import asarray\n",
    "\n",
    "# image = Image.open(jpg_file_path) <= values in the dict\n",
    "for k, v in array_dict[\"testing\"][\"flip\"].items():\n",
    "    image_array = asarray(v)\n",
    "    image_shape = image_array.shape\n",
    "    print(image_shape)\n",
    "    break\n",
    "# Image.fromarray(image_array) # To revert back from array to image\n",
    "\n",
    "# file_name = VideoID_FrameNumber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly sample one third of training data to get around memory issues due to a large number of image arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# from numpy import asarray\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# if not os.path.exists(\"./data/train_data.npy\"):\n",
    "#     print(\"train_data.npy does not exist. Create the file.\")\n",
    "#     import random\n",
    "#     random.seed(1)\n",
    "\n",
    "#     train_flip_sampled = random.sample(\n",
    "#         list(array_dict[\"training\"][\"flip\"].values()),\n",
    "#         int(len(array_dict[\"training\"][\"flip\"])/3)\n",
    "#         )\n",
    "#     train_notflip_sampled = random.sample(\n",
    "#         list(array_dict[\"training\"][\"notflip\"].values()),\n",
    "#         int(len(array_dict[\"training\"][\"notflip\"])/3)\n",
    "#         )\n",
    "\n",
    "#     train_data = []\n",
    "#     for i, img_list in enumerate([train_flip_sampled, train_notflip_sampled]):\n",
    "#         label_code = 1 # flip\n",
    "#         if i == 1:\n",
    "#             label_code = 0 # notflip\n",
    "\n",
    "#         for img in tqdm(img_list):\n",
    "#             image_array = asarray(img)\n",
    "#             train_data.append([image_array, label_code])\n",
    "\n",
    "#     np.save(\"./data/train_data.npy\", train_data)\n",
    "#     print(\"train_data saved.\")\n",
    "#     len(train_data)\n",
    "\n",
    "# else:\n",
    "#     print(\"train_data.npy already exists. Loading the file.\")\n",
    "#     train_data = np.load(\"./data/train_data.npy\", allow_pickle=True)\n",
    "#     print(\"train_data loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists(\"./data/test_data.npy\"):\n",
    "#     print(\"test_data.npy does not exist. Create the file.\")\n",
    "#     test_data = []\n",
    "#     for label in [\"flip\", \"notflip\"]:\n",
    "#         label_code = 1\n",
    "#         if label == \"notflip\":\n",
    "#             label_code = 0\n",
    "#         for name, img in tqdm(array_dict[\"testing\"][label].items()):\n",
    "#             image_array = asarray(img)\n",
    "#             test_data.append([image_array, label_code])\n",
    "\n",
    "#     np.save(\"./data/test_data.npy\", test_data)\n",
    "#     print(\"test_data saved.\")\n",
    "#     len(test_data)\n",
    "\n",
    "# else:\n",
    "#     print(\"test_data.npy already exists. Loading the file.\")\n",
    "#     test_data = np.load(\"./data/test_data.npy\", allow_pickle=True)\n",
    "#     print(\"test_data loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/python-image-classification-using-keras/\n",
    "\n",
    "# Importing all necessary libraries\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "# img_width, img_height = image_shape[:2]\n",
    "# Original shape of images: (1920, 1080, 3)\n",
    "img_width_reduced = 320\n",
    "img_height_reduced = 240\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (2, 2), input_shape=(img_width_reduced, img_height_reduced, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.metrics import Precision, Recall, F1Score\n",
    "# couldn't import F1Score, thus importing false and true positives and negatives.\n",
    "# Note that true negative is not an element of the f1 formula, but including it for more robust model performance.\n",
    "# from keras.metrics.metrics import FalsePositives, FalseNegatives, TrueNegatives, TruePositives\n",
    "# f1 = TruePositives() / (TruePositives() + 1/2*(FalsePositives() + FalseNegatives()))\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer='rmsprop',\n",
    "#             #   metrics=[Precision(), Recall(), F1Score(num_classes=2)])\n",
    "#               metrics=[FalsePositives(), FalseNegatives(), TrueNegatives(), TruePositives()])\n",
    "# => this set of metrics didn't result in a good f1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could try this if the above code does not result in a good f1 score.\n",
    "\n",
    "# source: https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
    "\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "            #   metrics=[Precision(), Recall(), F1Score(num_classes=2)])\n",
    "              metrics=[get_f1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's difficult to determine whether a neural network architecture is good or not without more context about the problem and data you are trying to solve. However, this architecture is a common and effective one for binary image classification tasks.\n",
    "\n",
    "It consists of convolutional layers with increasing filters followed by max-pooling layers to extract features from the input images. The flattened output from the convolutional layers is passed through a dense layer with a rectified linear activation function and a dropout layer to prevent overfitting. Finally, the output layer is a single neuron with a sigmoid activation function, which is suitable for binary classification problems.\n",
    "\n",
    "That being said, the optimal architecture for a specific task depends on various factors, such as the size and complexity of the dataset, the desired level of accuracy, and the available computing resources. It's usually a good idea to experiment with different architectures and compare their performance to find the best one for your specific problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates a Convolutional Neural Network (CNN) model using Keras, which is a popular deep learning library in Python.\n",
    "\n",
    "The model is defined using the Sequential() function, which allows you to build a linear stack of layers.\n",
    "\n",
    "The first layer in this model is a Conv2D layer, which stands for 2-dimensional convolution. It applies 32 filters to the input image, each filter with a size of 2x2. The input_shape parameter defines the dimensions of the input image as img_width_reduced, img_height_reduced, and 3 for RGB channels.\n",
    "\n",
    "The output of the Conv2D layer is passed through the Activation function with a Rectified Linear Unit (ReLU) activation function, which is commonly used in deep learning models.\n",
    "\n",
    "The next layer is a MaxPooling2D layer, which performs down-sampling by taking the maximum value within a 2x2 window. This reduces the spatial size of the output from the previous layer and helps to reduce overfitting.\n",
    "\n",
    "The Flatten layer flattens the output from the previous layer to a one-dimensional vector.\n",
    "\n",
    "The Dense layer is a fully connected layer with 64 neurons and is followed by the Activation function with ReLU activation function.\n",
    "\n",
    "A Dropout layer is added to randomly drop 50% of the neurons during training, which helps to reduce overfitting.\n",
    "\n",
    "Finally, a Dense layer with a single neuron and sigmoid activation function is added as the output layer, which is used for binary classification tasks. The sigmoid function squashes the output between 0 and 1, which can be interpreted as the probability of the input image belonging to the positive class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a code snippet for building and compiling a convolutional neural network (CNN) using the Keras API in Python.\n",
    "\n",
    "The Sequential() function creates an instance of a sequential neural network model, which allows you to build a model layer by layer.\n",
    "\n",
    "The Conv2D() function is used to add a 2D convolutional layer with 32 filters of size 2x2, to the model. The input_shape argument specifies the shape of the input image, which is (img_width_reduced, img_height_reduced, 3) where 3 represents the number of color channels in the image (RGB).\n",
    "\n",
    "The Activation() function is used to add a Rectified Linear Unit (ReLU) activation function to the output of the convolutional layer.\n",
    "\n",
    "The MaxPooling2D() function adds a max-pooling layer to the model, which reduces the dimensionality of the feature maps output by the convolutional layer by taking the maximum value within each local window of size 2x2.\n",
    "\n",
    "The commented out code lines are additional convolutional layers and max-pooling layers that can be added to the model if needed.\n",
    "\n",
    "The Flatten() function is used to convert the output from the convolutional and pooling layers to a 1D array, which can then be passed to a fully connected neural network layer.\n",
    "\n",
    "The Dense() function adds a fully connected neural network layer with 64 units to the model, followed by a ReLU activation function and a dropout layer that randomly sets 50% of the output units to zero during training to prevent overfitting.\n",
    "\n",
    "The last Dense() function adds an output layer to the model with a single unit and a sigmoid activation function, which is used for binary classification tasks.\n",
    "\n",
    "Finally, model.compile() is used to compile the model with a binary cross-entropy loss function, the RMSprop optimizer, and the accuracy metric, which will be used to evaluate the performance of the model during training.\n",
    "\n",
    "* RMSprop stands for Root Mean Square Propagation. It is a gradient descent-based optimization algorithm for neural networks, and it is used to update the weights of the network during training. RMSprop tries to resolve the problems of AdaGrad by using an exponentially decaying average of past gradients.\n",
    "\n",
    "    In RMSprop, the running average of the squared gradient is used to normalize the gradient before updating the weights. This has the effect of scaling down the learning rate for dimensions with high variance and scaling up the learning rate for dimensions with low variance.\n",
    "\n",
    "    RMSprop has been found to be effective in deep learning, particularly in recurrent neural networks, where it has been shown to converge faster than other optimization algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2392 images belonging to 2 classes.\n",
      "Found 597 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = './data/images/training'\n",
    "validation_data_dir = './data/images/testing'\n",
    "nb_train_samples = len(array_dict[\"training\"][\"flip\"]) + len(array_dict[\"training\"][\"notflip\"])\n",
    "nb_validation_samples = len(array_dict[\"testing\"][\"flip\"]) + len(array_dict[\"testing\"][\"notflip\"])\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "\t# rescale=1. / 255,\n",
    "\t# shear_range=0.2,\n",
    "\t# zoom_range=0.2,\n",
    "\t# horizontal_flip=True\n",
    "    )\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    # rescale=1. / 255\n",
    "    )\n",
    "\n",
    "import random\n",
    "random.seed(1)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "\ttrain_data_dir,\n",
    "\ttarget_size=(img_width_reduced, img_height_reduced),\n",
    "\tbatch_size=batch_size,\n",
    "\tclass_mode='binary',\n",
    "\tseed=random.seed(1))\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "\tvalidation_data_dir,\n",
    "\ttarget_size=(img_width_reduced, img_height_reduced),\n",
    "\tbatch_size=batch_size,\n",
    "\tclass_mode='binary',\n",
    "\tseed=random.seed(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "74/74 [==============================] - 193s 3s/step - loss: 0.7522 - get_f1: 0.9574 - val_loss: 0.0826 - val_get_f1: 0.9767\n",
      "Epoch 2/10\n",
      "74/74 [==============================] - 188s 3s/step - loss: 0.2436 - get_f1: 0.9603 - val_loss: 0.0643 - val_get_f1: 0.9848\n",
      "Epoch 3/10\n",
      "74/74 [==============================] - 177s 2s/step - loss: 0.1450 - get_f1: 0.9654 - val_loss: 2.3462 - val_get_f1: 0.8748\n",
      "Epoch 4/10\n",
      "74/74 [==============================] - 202s 3s/step - loss: 0.3584 - get_f1: 0.9636 - val_loss: 0.0632 - val_get_f1: 0.9823\n",
      "Epoch 5/10\n",
      "74/74 [==============================] - 180s 2s/step - loss: 0.1399 - get_f1: 0.9724 - val_loss: 0.0817 - val_get_f1: 0.9840\n",
      "Epoch 6/10\n",
      "74/74 [==============================] - 185s 3s/step - loss: 0.3331 - get_f1: 0.9696 - val_loss: 0.0778 - val_get_f1: 0.9847\n",
      "Epoch 7/10\n",
      "74/74 [==============================] - 175s 2s/step - loss: 0.0628 - get_f1: 0.9806 - val_loss: 0.0767 - val_get_f1: 0.9842\n",
      "Epoch 8/10\n",
      "74/74 [==============================] - 174s 2s/step - loss: 0.1270 - get_f1: 0.9765 - val_loss: 0.0528 - val_get_f1: 0.9918\n",
      "Epoch 9/10\n",
      "74/74 [==============================] - 179s 2s/step - loss: 0.1263 - get_f1: 0.9759 - val_loss: 0.0668 - val_get_f1: 0.9887\n",
      "Epoch 10/10\n",
      "74/74 [==============================] - 197s 3s/step - loss: 0.2241 - get_f1: 0.9674 - val_loss: 0.0636 - val_get_f1: 0.9911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2020182de50>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "\ttrain_generator,\n",
    "\tsteps_per_epoch=nb_train_samples // batch_size,\n",
    "\tepochs=epochs,\n",
    "\tvalidation_data=validation_generator,\n",
    "\tvalidation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step after calling model.fit_generator() with the specified arguments is to wait for the training process to complete. During training, the model will iterate over the training data in batches, compute the gradients, and update the model parameters to minimize the loss. The validation data is also used periodically to evaluate the model performance on unseen data and prevent overfitting.\n",
    "\n",
    "Once the training is complete, you can use the model.evaluate() method to compute the final loss and accuracy on the validation set, or use the model.predict() method to make predictions on new data. You can also save the trained model to disk using the model.save() method, so that you can reload it later and use it to make predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 17s 891ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.47      0.47       290\n",
      "         1.0       0.50      0.51      0.51       307\n",
      "\n",
      "    accuracy                           0.49       597\n",
      "   macro avg       0.49      0.49      0.49       597\n",
      "weighted avg       0.49      0.49      0.49       597\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = model.predict(validation_generator)\n",
    "\n",
    "# convert predictions from probabilities to labels\n",
    "y_pred = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
    "\n",
    "# print the classification report containing precision, recall and F1 score\n",
    "y_true = []\n",
    "for i in range(len(validation_generator)):\n",
    "    _, labels = validation_generator[i]\n",
    "    y_true.extend(labels)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 22s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4835640138408305"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Generate predictions\n",
    "y_pred = model.predict(validation_generator)\n",
    "y_pred = y_pred.round()\n",
    "\n",
    "# Extract true labels\n",
    "y_true = []\n",
    "for i in range(len(validation_generator)):\n",
    "    _, labels = validation_generator[i]\n",
    "    y_true.extend(labels)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 18s 889ms/step - loss: 0.0626 - get_f1: 0.9893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06256076693534851, 0.9892550110816956]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# from keras.preprocessing.image import load_img\n",
    "# from keras.preprocessing.image import img_to_array\n",
    "# from keras.applications.vgg16 import preprocess_input\n",
    "# from keras.applications.vgg16 import decode_predictions\n",
    "# from keras.applications.vgg16 import VGG16\n",
    "# import numpy as np\n",
    "\n",
    "# from keras.models import load_model\n",
    "\n",
    "# model = load_model('model_saved.h5')\n",
    "\n",
    "# image = load_img('v_data/test/planes/5.jpg', target_size=(224, 224))\n",
    "# img = np.array(image)\n",
    "# img = img / 255.0\n",
    "# img = img.reshape(1,224,224,3)\n",
    "# label = model.predict(img)\n",
    "# print(\"Predicted Class (0 - Cars , 1- Planes): \", label[0][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.geeksforgeeks.org/python-image-classification-using-keras/\n",
    "\n",
    "https://medium.com/techiepedia/binary-image-classifier-cnn-using-tensorflow-a3f5d6746697"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Python program to create\n",
    "# # # Image Classifier using CNN\n",
    "\n",
    "# # # Importing the required libraries\n",
    "# # import cv2\n",
    "# import os\n",
    "# import numpy as np\n",
    "# from random import shuffle\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # '''Setting up the env'''\n",
    "\n",
    "# # TRAIN_DIR = 'E:/dataset / Cats_vs_Dogs / train'\n",
    "# # TEST_DIR = 'E:/dataset / Cats_vs_Dogs / test1'\n",
    "# # IMG_SIZE = 50\n",
    "# LR = 1e-3\n",
    "\n",
    "\n",
    "# # '''Setting up the model which will help with tensorflow models'''\n",
    "# # MODEL_NAME = 'dogsvscats-{}-{}.model'.format(LR, '6conv-basic')\n",
    "\n",
    "# # '''Labelling the dataset'''\n",
    "# # def label_img(img):\n",
    "# # \tword_label = img.split('.')[-3]\n",
    "# # \t# DIY One hot encoder\n",
    "# # \tif word_label == 'cat': return [1, 0]\n",
    "# # \telif word_label == 'dog': return [0, 1]\n",
    "\n",
    "# # '''Creating the training data'''\n",
    "# # def create_train_data():\n",
    "# # \t# Creating an empty list where we should store the training data\n",
    "# # \t# after a little preprocessing of the data\n",
    "# # \ttraining_data = []\n",
    "\n",
    "# # \t# tqdm is only used for interactive loading\n",
    "# # \t# loading the training data\n",
    "# # \tfor img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "\n",
    "# # \t\t# labeling the images\n",
    "# # \t\tlabel = label_img(img)\n",
    "\n",
    "# # \t\tpath = os.path.join(TRAIN_DIR, img)\n",
    "\n",
    "# # \t\t# loading the image from the path and then converting them into\n",
    "# # \t\t# grayscale for easier covnet prob\n",
    "# # \t\timg = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# # \t\t# resizing the image for processing them in the covnet\n",
    "# # \t\timg = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "# # \t\t# final step-forming the training data list with numpy array of the images\n",
    "# # \t\ttraining_data.append([np.array(img), np.array(label)])\n",
    "\n",
    "# # \t# shuffling of the training data to preserve the random state of our data\n",
    "# # \tshuffle(training_data)\n",
    "\n",
    "# # \t# saving our trained data for further uses if required\n",
    "# # \tnp.save('train_data.npy', training_data)\n",
    "# # \treturn training_data\n",
    "\n",
    "# # '''Processing the given test data'''\n",
    "# # # Almost same as processing the training data but\n",
    "# # # we dont have to label it.\n",
    "# # def process_test_data():\n",
    "# # \ttesting_data = []\n",
    "# # \tfor img in tqdm(os.listdir(TEST_DIR)):\n",
    "# # \t\tpath = os.path.join(TEST_DIR, img)\n",
    "# # \t\timg_num = img.split('.')[0]\n",
    "# # \t\timg = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "# # \t\timg = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "# # \t\ttesting_data.append([np.array(img), img_num])\n",
    "\t\t\n",
    "# # \tshuffle(testing_data)\n",
    "# # \tnp.save('test_data.npy', testing_data)\n",
    "# # \treturn testing_data\n",
    "\n",
    "# # '''Running the training and the testing in the dataset for our model'''\n",
    "# # train_data = create_train_data()\n",
    "# # test_data = process_test_data()\n",
    "\n",
    "# # # train_data = np.load('train_data.npy')\n",
    "# # # test_data = np.load('test_data.npy')\n",
    "# '''Creating the neural network using tensorflow'''\n",
    "# # Importing the required libraries\n",
    "# import tflearn\n",
    "# from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "# from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "# from tflearn.layers.estimator import regression\n",
    "\n",
    "# import tensorflow as tf\n",
    "# tf.compat.v1.reset_default_graph()\n",
    "# convnet = input_data(shape =[None, 1920, 1080, 3], name ='input')\n",
    "\n",
    "# convnet = conv_2d(convnet, 32, 5, activation ='relu')\n",
    "# convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "# # convnet = conv_2d(convnet, 64, 5, activation ='relu')\n",
    "# # convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "# # convnet = conv_2d(convnet, 128, 5, activation ='relu')\n",
    "# # convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "# # convnet = conv_2d(convnet, 64, 5, activation ='relu')\n",
    "# # convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "# # convnet = conv_2d(convnet, 32, 5, activation ='relu')\n",
    "# # convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "# convnet = fully_connected(convnet, 1024, activation ='relu')\n",
    "# convnet = dropout(convnet, 0.8)\n",
    "\n",
    "# convnet = fully_connected(convnet, 2, activation ='softmax')\n",
    "# convnet = regression(convnet, optimizer ='adam', learning_rate = LR,\n",
    "# \tloss ='categorical_crossentropy', name ='targets')\n",
    "\n",
    "# model = tflearn.DNN(convnet, tensorboard_dir ='log')\n",
    "\n",
    "# # Splitting the testing data and training data\n",
    "# # train = train_data[:-500]\n",
    "# # test = train_data[-500:]\n",
    "\n",
    "# '''Setting up the features and labels'''\n",
    "# # X-Features & Y-Labels\n",
    "\n",
    "# train_X = np.array([i[0] for i in train_data]).reshape(-1, 1920, 1080, 3)\n",
    "# train_y = np.array([i[1] for i in train_data])\n",
    "# test_X = np.array([i[0] for i in test_data]).reshape(-1, 1920, 1080, 3)\n",
    "# test_y = np.array([i[1] for i in test_data])\n",
    "\n",
    "# '''Fitting the data into our model'''\n",
    "# # epoch = 5 taken\n",
    "# model.fit({'input': train_X}, {'targets': train_y}, n_epoch = 5,\n",
    "# \tvalidation_set =({'input': test_X}, {'targets': test_y}),\n",
    "# \tsnapshot_step = 500, show_metric = True, run_id = \"initial.model\")\n",
    "# model.save(\"initial.model\")\n",
    "\n",
    "# '''Testing the data'''\n",
    "# import matplotlib.pyplot as plt\n",
    "# # if you need to create the data:\n",
    "# # test_data = process_test_data()\n",
    "# # if you already have some saved:\n",
    "# test_data = np.load('test_data.npy')\n",
    "\n",
    "# fig = plt.figure()\n",
    "\n",
    "# for num, data in enumerate(test_data[:20]):\n",
    "# \t# cat: [1, 0]\n",
    "# \t# dog: [0, 1]\n",
    "\t\n",
    "# \timg_num = data[1]\n",
    "# \timg_data = data[0]\n",
    "\t\n",
    "# \ty = fig.add_subplot(4, 5, num + 1)\n",
    "# \torig = img_data\n",
    "# \tdata = img_data.reshape(1920, 1080, 3)\n",
    "\n",
    "# \t# model_out = model.predict([data])[0]\n",
    "# \tmodel_out = model.predict([data])[0]\n",
    "\t\n",
    "# \tif np.argmax(model_out) == 1: str_label ='Dog'\n",
    "# \telse: str_label ='Cat'\n",
    "\t\t\n",
    "# \ty.imshow(orig, cmap ='gray')\n",
    "# \tplt.title(str_label)\n",
    "# \ty.axes.get_xaxis().set_visible(False)\n",
    "# \ty.axes.get_yaxis().set_visible(False)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
