{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Table of Content</b>\n",
    "\n",
    "0. Import functions\n",
    "\n",
    "1. Download ZIP file from Google Drive and unzip in into local drive\n",
    "\n",
    "2. Load image files and convert them into arrays"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>0. Import functions</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.load import check_file_downloaded, extract_zip_file, load_images\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>1. Download ZIP file from Google Drive and unzip in into local drive</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Details of the source file in G Drive\n",
    "file_id = \"1KDQBTbo5deKGCdVV_xIujscn5ImxW4dm\"\n",
    "file_url = f\"https://drive.google.com/file/d/{file_id}\"\n",
    "zip_file_name = \"images.zip\"\n",
    "\n",
    "# Details of local directories\n",
    "root_path = os.getcwd()\n",
    "download_path = root_path + \"\\\\\" + \"data\"\n",
    "zip_file_path = download_path + \"\\\\\" + zip_file_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the source file from G Drive if the file does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File images.zip already exists in c:\\Users\\Admin\\Documents\\GitHub\\Apziva\\lnaNWaYIRf6JhvHJ\\data.\n"
     ]
    }
   ],
   "source": [
    "os.chdir(download_path)\n",
    "file_exists = os.path.exists(zip_file_name)\n",
    "if file_exists:\n",
    "    print(f\"File {zip_file_name} already exists in {download_path}.\")\n",
    "else:\n",
    "    print(\"Downloading file from Google Drive.\")\n",
    "    print(\"This could take a few minutes.\")\n",
    "    !gdown 1KDQBTbo5deKGCdVV_xIujscn5ImxW4dm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the downloading was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File images.zip exist in c:\\Users\\Admin\\Documents\\GitHub\\Apziva\\lnaNWaYIRf6JhvHJ\\data!\n"
     ]
    }
   ],
   "source": [
    "check_file_downloaded(file_name=zip_file_name, default_path=root_path, download_path=download_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images.zip already extracted in c:\\Users\\Admin\\Documents\\GitHub\\Apziva\\lnaNWaYIRf6JhvHJ\\data.\n"
     ]
    }
   ],
   "source": [
    "extract_zip_file(zip_file_path, download_path, zip_file_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>2. Load image files and convert them into arrays</b>\n",
    "\n",
    "Load images as is for efficiency and memory saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files in c:\\Users\\Admin\\Documents\\GitHub\\Apziva\\lnaNWaYIRf6JhvHJ\\data\\images\n",
      "Loading files in c:\\Users\\Admin\\Documents\\GitHub\\Apziva\\lnaNWaYIRf6JhvHJ\\data\\images\\testing\n",
      "Loading files in c:\\Users\\Admin\\Documents\\GitHub\\Apziva\\lnaNWaYIRf6JhvHJ\\data\\images\\testing\\flip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 290/290 [00:00<00:00, 812.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files in c:\\Users\\Admin\\Documents\\GitHub\\Apziva\\lnaNWaYIRf6JhvHJ\\data\\images\\testing\\notflip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:00<00:00, 1136.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files in c:\\Users\\Admin\\Documents\\GitHub\\Apziva\\lnaNWaYIRf6JhvHJ\\data\\images\\training\n",
      "Loading files in c:\\Users\\Admin\\Documents\\GitHub\\Apziva\\lnaNWaYIRf6JhvHJ\\data\\images\\training\\flip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1162/1162 [00:01<00:00, 1082.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files in c:\\Users\\Admin\\Documents\\GitHub\\Apziva\\lnaNWaYIRf6JhvHJ\\data\\images\\training\\notflip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1230/1230 [00:01<00:00, 954.33it/s]\n"
     ]
    }
   ],
   "source": [
    "array_dict = load_images(download_path, as_array=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(array_dict[\"testing\"][\"flip\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 1080, 3)\n"
     ]
    }
   ],
   "source": [
    "from numpy import asarray\n",
    "\n",
    "# image = Image.open(jpg_file_path) <= values in the dict\n",
    "for k, v in array_dict[\"testing\"][\"flip\"].items():\n",
    "    image_array = asarray(v)\n",
    "    print(image_array.shape)\n",
    "    break\n",
    "# Image.fromarray(image_array) # To revert back from array to image\n",
    "\n",
    "# file_name = VideoID_FrameNumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1162/1162 [00:00<00:00, 291337.27it/s]\n",
      "100%|██████████| 1230/1230 [00:00<00:00, 246676.58it/s]\n",
      "100%|██████████| 290/290 [00:10<00:00, 26.98it/s]\n",
      "100%|██████████| 307/307 [00:15<00:00, 20.45it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "for train_test in [\"training\", \"testing\"]:\n",
    "    for label in [\"flip\", \"notflip\"]:\n",
    "        for name, img in tqdm(array_dict[train_test][label].items()):\n",
    "            # image_array = asarray(img)\n",
    "            if train_test == \"training\":\n",
    "                # train_data.append([image_array, label])\n",
    "                pass\n",
    "            else:\n",
    "                image_array = asarray(img)\n",
    "                test_data.append([image_array, label])\n",
    "\n",
    "# np.save('train_data.npy', train_data)\n",
    "np.save('test_data.npy', test_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- https://www.geeksforgeeks.org/python-image-classification-using-keras/\n",
    "\n",
    "https://www.thepythoncode.com/article/image-classification-keras-python\n",
    "\n",
    "https://stackabuse.com/image-recognition-in-python-with-tensorflow-and-keras/\n",
    "\n",
    "# Try Google Colab for faster computation using GPU. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.load('test_data.npy', allow_pickle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.geeksforgeeks.org/python-image-classification-using-keras/\n",
    "\n",
    "https://medium.com/techiepedia/binary-image-classifier-cnn-using-tensorflow-a3f5d6746697"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Python program to create\n",
    "# # Image Classifier using CNN\n",
    "\n",
    "# # Importing the required libraries\n",
    "# import cv2\n",
    "# import os\n",
    "# import numpy as np\n",
    "# from random import shuffle\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# '''Setting up the env'''\n",
    "\n",
    "# TRAIN_DIR = 'E:/dataset / Cats_vs_Dogs / train'\n",
    "# TEST_DIR = 'E:/dataset / Cats_vs_Dogs / test1'\n",
    "# IMG_SIZE = 50\n",
    "# LR = 1e-3\n",
    "\n",
    "\n",
    "# '''Setting up the model which will help with tensorflow models'''\n",
    "# MODEL_NAME = 'dogsvscats-{}-{}.model'.format(LR, '6conv-basic')\n",
    "\n",
    "# '''Labelling the dataset'''\n",
    "# def label_img(img):\n",
    "# \tword_label = img.split('.')[-3]\n",
    "# \t# DIY One hot encoder\n",
    "# \tif word_label == 'cat': return [1, 0]\n",
    "# \telif word_label == 'dog': return [0, 1]\n",
    "\n",
    "# '''Creating the training data'''\n",
    "# def create_train_data():\n",
    "# \t# Creating an empty list where we should store the training data\n",
    "# \t# after a little preprocessing of the data\n",
    "# \ttraining_data = []\n",
    "\n",
    "# \t# tqdm is only used for interactive loading\n",
    "# \t# loading the training data\n",
    "# \tfor img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "\n",
    "# \t\t# labeling the images\n",
    "# \t\tlabel = label_img(img)\n",
    "\n",
    "# \t\tpath = os.path.join(TRAIN_DIR, img)\n",
    "\n",
    "# \t\t# loading the image from the path and then converting them into\n",
    "# \t\t# grayscale for easier covnet prob\n",
    "# \t\timg = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# \t\t# resizing the image for processing them in the covnet\n",
    "# \t\timg = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "# \t\t# final step-forming the training data list with numpy array of the images\n",
    "# \t\ttraining_data.append([np.array(img), np.array(label)])\n",
    "\n",
    "# \t# shuffling of the training data to preserve the random state of our data\n",
    "# \tshuffle(training_data)\n",
    "\n",
    "# \t# saving our trained data for further uses if required\n",
    "# \tnp.save('train_data.npy', training_data)\n",
    "# \treturn training_data\n",
    "\n",
    "# '''Processing the given test data'''\n",
    "# # Almost same as processing the training data but\n",
    "# # we dont have to label it.\n",
    "# def process_test_data():\n",
    "# \ttesting_data = []\n",
    "# \tfor img in tqdm(os.listdir(TEST_DIR)):\n",
    "# \t\tpath = os.path.join(TEST_DIR, img)\n",
    "# \t\timg_num = img.split('.')[0]\n",
    "# \t\timg = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "# \t\timg = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "# \t\ttesting_data.append([np.array(img), img_num])\n",
    "\t\t\n",
    "# \tshuffle(testing_data)\n",
    "# \tnp.save('test_data.npy', testing_data)\n",
    "# \treturn testing_data\n",
    "\n",
    "# '''Running the training and the testing in the dataset for our model'''\n",
    "# train_data = create_train_data()\n",
    "# test_data = process_test_data()\n",
    "\n",
    "# # train_data = np.load('train_data.npy')\n",
    "# # test_data = np.load('test_data.npy')\n",
    "# '''Creating the neural network using tensorflow'''\n",
    "# # Importing the required libraries\n",
    "# import tflearn\n",
    "# from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "# from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "# from tflearn.layers.estimator import regression\n",
    "\n",
    "# import tensorflow as tf\n",
    "# tf.compat.v1.reset_default_graph()\n",
    "# convnet = input_data(shape =[None, IMG_SIZE, IMG_SIZE, 1], name ='input')\n",
    "\n",
    "# convnet = conv_2d(convnet, 32, 5, activation ='relu')\n",
    "# convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "# convnet = conv_2d(convnet, 64, 5, activation ='relu')\n",
    "# convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "# convnet = conv_2d(convnet, 128, 5, activation ='relu')\n",
    "# convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "# convnet = conv_2d(convnet, 64, 5, activation ='relu')\n",
    "# convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "# convnet = conv_2d(convnet, 32, 5, activation ='relu')\n",
    "# convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "# convnet = fully_connected(convnet, 1024, activation ='relu')\n",
    "# convnet = dropout(convnet, 0.8)\n",
    "\n",
    "# convnet = fully_connected(convnet, 2, activation ='softmax')\n",
    "# convnet = regression(convnet, optimizer ='adam', learning_rate = LR,\n",
    "# \tloss ='categorical_crossentropy', name ='targets')\n",
    "\n",
    "# model = tflearn.DNN(convnet, tensorboard_dir ='log')\n",
    "\n",
    "# # Splitting the testing data and training data\n",
    "# train = train_data[:-500]\n",
    "# test = train_data[-500:]\n",
    "\n",
    "# '''Setting up the features and labels'''\n",
    "# # X-Features & Y-Labels\n",
    "\n",
    "# X = np.array([i[0] for i in train]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "# Y = np.array([i[1] for i in train])\n",
    "# test_x = np.array([i[0] for i in test]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "# test_y = np.array([i[1] for i in test])\n",
    "\n",
    "# '''Fitting the data into our model'''\n",
    "# # epoch = 5 taken\n",
    "# model.fit({'input': X}, {'targets': Y}, n_epoch = 5,\n",
    "# \tvalidation_set =({'input': test_x}, {'targets': test_y}),\n",
    "# \tsnapshot_step = 500, show_metric = True, run_id = MODEL_NAME)\n",
    "# model.save(MODEL_NAME)\n",
    "\n",
    "# '''Testing the data'''\n",
    "# import matplotlib.pyplot as plt\n",
    "# # if you need to create the data:\n",
    "# # test_data = process_test_data()\n",
    "# # if you already have some saved:\n",
    "# test_data = np.load('test_data.npy')\n",
    "\n",
    "# fig = plt.figure()\n",
    "\n",
    "# for num, data in enumerate(test_data[:20]):\n",
    "# \t# cat: [1, 0]\n",
    "# \t# dog: [0, 1]\n",
    "\t\n",
    "# \timg_num = data[1]\n",
    "# \timg_data = data[0]\n",
    "\t\n",
    "# \ty = fig.add_subplot(4, 5, num + 1)\n",
    "# \torig = img_data\n",
    "# \tdata = img_data.reshape(IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "# \t# model_out = model.predict([data])[0]\n",
    "# \tmodel_out = model.predict([data])[0]\n",
    "\t\n",
    "# \tif np.argmax(model_out) == 1: str_label ='Dog'\n",
    "# \telse: str_label ='Cat'\n",
    "\t\t\n",
    "# \ty.imshow(orig, cmap ='gray')\n",
    "# \tplt.title(str_label)\n",
    "# \ty.axes.get_xaxis().set_visible(False)\n",
    "# \ty.axes.get_yaxis().set_visible(False)\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
